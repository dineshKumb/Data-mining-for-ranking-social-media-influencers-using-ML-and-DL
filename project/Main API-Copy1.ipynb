#!/usr/bin/env python
# coding: utf-8

# In[1]:


#pip install webdriver_manager


# In[52]:


#pip install keybert


# In[49]:


#pip install keybert[flair]


# In[2]:


from googleapiclient.discovery import build
import pandas as pd
#import seaborn as sns


import re
import requests



# In[2]:

import streamlit as st
import login
api_key='AIzaSyDjF6w3QnVjpYhMjA6oIy3pf-12BKbMRgI'
channel_ids=channelID

youtube=build('youtube','v3', developerKey=api_key)


# In[5]:


def get_channel_stats(youtube, channel_ids): 
    request=youtube.channels().list(
        part='snippet,contentDetails,statistics',
        id=','.join(channel_ids))
    response= request.execute()
    all_data=[]
    for i in range(len(response['items'])):
        data = dict(Channel_name=response['items'][i]['snippet']['title'],
                Description=response['items'][i]['snippet']['description'],
                Country=response['items'][i]['snippet']['country'],
                Subscribers=response['items'][i]['statistics']['subscriberCount'],
                Views=response['items'][i]['statistics']['viewCount'],
                Total_videos=response['items'][i]['statistics']['videoCount'],
                playlist_id=response['items'][i]['contentDetails']['relatedPlaylists']['uploads'])
                #country_name=response['item'][i][]
        all_data.append(data)  
        return all_data
get_channel_stats(youtube, channel_ids)


# In[6]:


get_channel_stats(youtube, channel_ids)


# In[7]:


channel_satistics=get_channel_stats(youtube, channel_ids)


# In[8]:


channel_data=pd.DataFrame(channel_satistics)


# In[9]:


channel_data


# In[10]:


playlist_id = channel_data.loc[channel_data['Channel_name']==channel_data['Channel_name'], 'playlist_id'].iloc[0]
playlist_id


# In[11]:


channel_data['Subscribers']=pd.to_numeric(channel_data['Subscribers'])
channel_data['Views']=pd.to_numeric(channel_data['Views'])
channel_data['Total_videos']=pd.to_numeric(channel_data['Total_videos'])


# In[12]:


channel_data.dtypes


# In[13]:


channel_data


# All video details of the channel

# In[14]:


def get_video_ids(youtube, playlist_id):
    
    request = youtube.playlistItems().list(
                part='contentDetails',
                playlistId = playlist_id,
                maxResults = 50)
    response = request.execute()
    
    video_ids = []
    
    for i in range(len(response['items'])):
        video_ids.append(response['items'][i]['contentDetails']['videoId'])
        
    next_page_token = response.get('nextPageToken')
    more_pages = True
    
    while more_pages:
        if next_page_token is None:
            more_pages = False
        else:
            request = youtube.playlistItems().list(
                        part='contentDetails',
                        playlistId = playlist_id,
                        maxResults = 50,
                        pageToken = next_page_token)
            response = request.execute()
    
            for i in range(len(response['items'])):
                video_ids.append(response['items'][i]['contentDetails']['videoId'])
            
            next_page_token = response.get('nextPageToken')
        
    return video_ids


# In[15]:


video_ids1=get_video_ids(youtube, playlist_id)
video_ids1


# Function to get video details 

# In[31]:


def get_video_details(youtube, video_ids1):
    all_video_stats=[]
    
    for i in range(0,len(video_ids1), 50):
        request=youtube.videos().list(
            part='snippet,statistics',
            id=','.join(video_ids1[i:i+50]))
        response=request.execute()
    
        for video in response['items']:
            
            video_stats=dict(Title=video['snippet']['title'],
                        Published_date=video['snippet']['publishedAt'],
                        Views=video['statistics']['viewCount'],
                        Likes=video['statistics']['likeCount'],
                        Comments = video['statistics']['commentCount'],
                        Description=video['snippet']['description'],
                        #Country=video['snippet']['country']
                        )
            all_video_stats.append(video_stats)

    return all_video_stats


# In[32]:


video_data=get_video_details(youtube, video_ids1)
video_details=pd.DataFrame(video_data)


# In[33]:


video_details.duplicated().sum()


# In[34]:


video_details.loc[video_details.duplicated(keep=False),:]


# In[35]:


video_details['Published_date']=pd.to_datetime(video_details['Published_date']).dt.date
video_details['Views']=pd.to_numeric(video_details['Views'])
video_details['Likes']=pd.to_numeric(video_details['Likes'])
video_details['Comments']=pd.to_numeric(video_details['Comments'])
video_details_filtered=video_details.drop_duplicates()


# In[36]:


video_details_filtered['Video_Id']=video_ids1


# In[37]:


st.table(video_details_filtered)


# In[38]:


top10_videos=video_details_filtered.sort_values(by='Views', ascending=False).head(15)
top10_videos


# In[39]:


sns.set(rc={'figure.figsize':(10,8)})
ax1=sns.barplot(x='Views',y='Title',data=top10_videos)


# In[40]:


top10_videos=video_details_filtered.sort_values(by='Likes', ascending=False).head(15)
sns.set(rc={'figure.figsize':(10,8)})
ax1=sns.barplot(x='Likes',y='Title',data=top10_videos)


# In[41]:


top10_videos=video_details_filtered.sort_values(by='Comments', ascending=False).head(15)
sns.set(rc={'figure.figsize':(10,8)})
ax1=sns.barplot(x='Comments',y='Title',data=top10_videos)


# https://www.youtube.com/watch?v=Ung-SWAEngc&ab_channel=AhmedBesbes

# In[46]:


title=[]
for i in video_details_filtered.Title:
    title.append(i)


# In[58]:


Title=" ".join(map(str,title))


# In[64]:


discription=[]
for i in video_details_filtered.Description:
    discription.append(i)


# In[65]:


Discription=" ".join(map(str,discription))


# In[55]:


from keybert import KeyBERT


# In[60]:


model=KeyBERT('distilbert-base-nli-mean-tokens')
keywords=model.extract_keywords(Title)


# In[63]:


keywords[:5]


# In[67]:


model1=KeyBERT('distilbert-base-nli-mean-tokens')
Description_keywords=model1.extract_keywords(Discription)


# In[68]:


Description_keywords


# In[78]:


# latest_Discription=" ".join(map(str,video_details_filtered.Description[0]))

model2=KeyBERT('distilbert-base-nli-mean-tokens')
latest_Description_keywords=model1.extract_keywords(video_details_filtered.Title[2])
latest_Description_keywords


# In[42]:


video_details_filtered.to_csv('video_data.csv')


# In[39]:


sortedbycomment=video_details_filtered.sort_values('Comments')
sortedbycomment


# In[48]:


sortedcomm=sortedbycomment[:25]
fifty_comments_videos=sortedcomm['Video_Id']


# In[49]:



#video_ids2=video_ids1[:50]    # Replace this YouTube video ID with your own.

box = [['Comment', 'Likes', 'Reply Count']]

def scrape_comments_with_replies(fifty_comments_videos):
        for ID in fifty_comments_videos:
            data = youtube.commentThreads().list(part='snippet', videoId=ID, maxResults='100', textFormat="plainText").execute()

            for i in data["items"]:
                comment = i["snippet"]['topLevelComment']["snippet"]["textDisplay"]
                likes = i["snippet"]['topLevelComment']["snippet"]['likeCount']
                replies = i["snippet"]['totalReplyCount']

                box.append([comment, likes, replies])

                totalReplyCount = i["snippet"]['totalReplyCount']

                if totalReplyCount > 0:

                    parent = i["snippet"]['topLevelComment']["id"]

                    data2 = youtube.comments().list(part='snippet', maxResults='100', parentId=parent,
                                                    textFormat="plainText").execute()

                    for i in data2["items"]:
                        comment = i["snippet"]["textDisplay"]
                        likes = i["snippet"]['likeCount']
                        replies = ""

                        box.append([comment, likes, replies])

            while ("nextPageToken" in data):

                data = youtube.commentThreads().list(part='snippet', videoId=ID, pageToken=data["nextPageToken"],
                                                     maxResults='100', textFormat="plainText").execute()

                for i in data["items"]:
                    comment = i["snippet"]['topLevelComment']["snippet"]["textDisplay"]
                    likes = i["snippet"]['topLevelComment']["snippet"]['likeCount']
                    replies = i["snippet"]['totalReplyCount']

                    box.append([comment, likes, replies])

                    totalReplyCount = i["snippet"]['totalReplyCount']

                    if totalReplyCount > 0:

                        parent = i["snippet"]['topLevelComment']["id"]

                        data2 = youtube.comments().list(part='snippet', maxResults='100', parentId=parent,
                                                        textFormat="plainText").execute()

                        for i in data2["items"]:
                            comment = i["snippet"]["textDisplay"]
                            likes = i["snippet"]['likeCount']
                            replies = ''

                            box.append([comment, likes, replies])

            df = pd.DataFrame({'Comment': [i[0] for i in box],'Likes': [i[1] for i in box], 'Reply Count': [i[2] for i in box]})

        #df.to_csv('youtube-comments.csv', index=False, header=False)
        #return "Successful! Check the CSV file that you have just created."


scrape_comments_with_replies(fifty_comments_videos)


# In[3]:


#video_dataset=pd.read_csv("video_data.csv")


# In[4]:


video_dataset.info()


# In[ ]:


video_dataset[["year", "month", "day"]] = video_dataset["Published_date"].str.split("-", expand = True)


# In[86]:


sorted_by_date=video_dataset.sort_values(by="Published_date")


# In[102]:


sorted_by_date = sorted_by_date.astype({"year": int}, errors='raise') 
sorted_by_date = sorted_by_date.astype({"month": int}, errors='raise') 
sorted_by_date = sorted_by_date.astype({"day": int}, errors='raise') 

#sorted_by_date['year']


# In[6]:


Views=pd.DataFrame(video_dataset['Views'].describe())
Views


# In[7]:


Likes=pd.DataFrame(video_dataset['Likes'].describe())
Likes


# In[8]:


Comments=pd.DataFrame(video_dataset['Comments'].describe())
Comments


# In[35]:


import matplotlib.pyplot as plt
names = ['Views','Likes','Comments']
values = [sum(video_dataset['Views']),sum(video_dataset['Likes']),sum(video_dataset['Comments'])]
plt.figure(figsize=(15,5))
plt.subplot(131)
plt.bar(names, values)
plt.suptitle('Categorical Plotting')
plt.show()


# In[77]:


names = ['Views','Likes']
values = [sum(video_dataset['Views']),sum(video_dataset['Likes'])]
plt.figure(figsize=(15,5))
plt.subplot(131)
plt.bar(names, values)
plt.suptitle('Total Views vs Likes')
names = ['Likes','Comments']
values = [sum(video_dataset['Likes']),sum(video_dataset['Comments'])]
plt.figure(figsize=(15,5))
plt.subplot(131)
plt.bar(names, values)
plt.suptitle('Total Likes vs Comments')
names = ['Views','Comments']
values = [sum(video_dataset['Views']),sum(video_dataset['Comments'])]
plt.figure(figsize=(15,5))
plt.subplot(131)
plt.bar(names, values)
plt.suptitle('Total Views vs Comments')

plt.show()


# In[75]:


names = ['Views','Likes','Comments']
values = [video_dataset['Views'].describe()[1],video_dataset['Likes'].describe()[1],video_dataset['Comments'].describe()[1]]
plt.figure(figsize=(15,5))
plt.subplot(133)
plt.plot(names, values)
plt.suptitle('Mean')
plt.show()


# In[151]:


year=sorted_by_date.groupby(['year'])
ax1=sns.barplot(y='Views',x='Likes',data=year.first(), hue=sorted_by_date.year.unique())
plt.show()


# In[152]:


year=sorted_by_date.groupby(['year'])
ax1=sns.barplot(y='Views',x='Comments',data=year.first(), hue=sorted_by_date.year.unique())
plt.show()


# In[ ]:





# In[ ]:




